---
title: "MASH Null -- Real Data (GTEx random set)"
author: "Yuxin Zou"
date: 2018-08-23
output: 
  workflowr::wflow_html:
    code_folding: hide
---

```{r}
library(mashr)
# source('../code/estimate_cor.R')
# source('../code/generateDataV.R')
library(knitr)
library(kableExtra)
```

```{r read data}
gtex <- readRDS(gzcon(url("https://github.com/stephenslab/gtexresults/blob/master/data/MatrixEQTLSumStats.Portable.Z.rds?raw=TRUE")))

data1 = list(bhat = gtex$random.b, shat = gtex$random.s, zhat = gtex$random.z)
data2 = list(bhat = gtex$random.test.b, shat = gtex$random.test.s, zhat = gtex$random.test.z)
```

Permute the effect size in each tissue, to break the sharing
```{r}
set.seed(1)
n1 = nrow(data1$bhat); p1 = ncol(data1$bhat)
n2 = nrow(data2$bhat); p2 = ncol(data2$bhat)
data1.p = data1
data2.p = data2
for(r in 1:p1){
  permute1 = sample(1:n1, n1, replace = FALSE)
  data1.p$bhat[,r] = data1$bhat[permute1,r]
  data1.p$shat[,r] = data1$shat[permute1,r]
  data1.p$zhat[,r] = data1$zhat[permute1,r]
  row.names(data1.p$bhat) = row.names(data1.p$shat) = row.names(data1.p$zhat) = row.names(data1$bhat)[permute1]
  
  permute2 = sample(1:n2, n2, replace = FALSE)
  data2.p$bhat[,r] = data2$bhat[permute2,r]
  data2.p$shat[,r] = data2$shat[permute2,r]
  data2.p$zhat[,r] = data2$zhat[permute2,r]
  row.names(data2.p$bhat) = row.names(data2.p$shat) = row.names(data2.p$zhat) = row.names(data2$bhat)[permute2]
}

```

There are two random sets. We select the samples with max $|Z_{jr}|<3.5$ from each one as the null set. The null data 1 has 18189 samples. The null data 2 has 25718 samples.

Select null data:
```{r}
data1.z.p = apply(abs(data1.p$zhat), 1, max)
data1.p.null.ind = which(data1.z.p < 3.5)

data2.z.p = apply(abs(data2.p$zhat), 1, max)
data2.p.null.ind = which(data2.z.p < 3.5)

data1.p.null = lapply(data1.p, function(l) l[data1.p.null.ind, ])
data2.p.null = lapply(data2.p, function(l) l[data2.p.null.ind, ])

m.data1.p.null = mash_set_data(Bhat = data1.p.null$bhat, Shat = data1.p.null$shat)
m.data2.p.null = mash_set_data(Bhat = data2.p.null$bhat, Shat = data2.p.null$shat)
```

Estimate data driven covariance matrices from data 1:
```{r}
U.pca = cov_pca(m.data1.p.null, 3)
U.ed = cov_ed(m.data1.p.null, U.pca)
```

Estimate noise correlation from data 2
```{r}
Vhat = estimate_null_correlation(m.data2.p.null)
```

Fit mash model on data 2
```{r}
m.data2.p.null.Vhat = mash_set_data(Bhat = data2.p.null$bhat, Shat = data2.p.null$shat, V = Vhat)
U.c = cov_canonical(m.data2.p.null.Vhat)
m.model2.p.null = mash(m.data2.p.null.Vhat, c(U.c, U.ed), outputlevel = 1)
```
```{r}
barplot(get_estimated_pi(m.model2.p.null), las=2, cex.names = 0.7)
```

Posterior on the data 1
```{r}
m.data1.p.null.Vhat = mash_set_data(Bhat = m.data1.p.null$Bhat, Shat = m.data1.p.null$Shat, V = Vhat)
m.model2.p.null$result = mash_compute_posterior_matrices(m.model2.p.null, m.data1.p.null.Vhat)
```

Using lfsr, there are `r length(get_significant_results(m.model2.p.null))` significance samples in data 1. There are `r length(get_significant_results(m.model2.p.null, sig_fn = get_lfdr))` significance samples in data 1, using lfdr.
