---
title: "Comparing with mean (with signal) Recover"
author: "Yuxin Zou"
date: 2018-04-26
output: 
  html_document:
    code_folding: hide
---
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the R version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r R-version, echo=FALSE, results='asis'}
```

```{r, echo=FALSE}
# TEMPORARY.
knitr::opts_chunk$set(eval = TRUE)
```

```{r, echo=FALSE}
library(mashr)
library(corrplot)
source('../code/sim_mean_sig.R')
source('../code/MashSource.R')
```

The data contains 10 conditions with 10% non-null samples. For the non-null samples, it has equal effects in the first c conditions. 

Let L be the contrast matrix that subtract mean from each sample.

$$\hat{\delta}_{j}|\delta_{j} \sim N(\delta_{j}, \frac{1}{2}LL')$$
90% of the true deviations are 0. 10% of the deviation $\delta_{j}$ has correlation that the first c conditions are negatively correlated with the rest conditions.


We set $c = 2$.
```{r data}
set.seed(1)
R = 10
C = 2
data = sim.mean.sig(nsamp=10000, ncond=C)
```

# Discard last column

## Mash contrast model
```{r}
L = matrix(-1/R, R, R)
L[cbind(1:R,1:R)] = (R-1)/R
L.10 = L[1:(R-1),]
row.names(L.10) = seq(1,R-1)
mash_data = mash_set_data(Bhat=data$Chat, Shat=data$Shat)
mash_data_L.10 = mash_set_data_contrast(mash_data, L.10)
```

```{r}
U.c = cov_canonical(mash_data_L.10)

# data driven
# select max
m.1by1 = mash_1by1(mash_data_L.10)
strong = get_significant_results(m.1by1,0.05)
# center Z
mash_data_L.center = mash_data_L.10
mash_data_L.center$Bhat = mash_data_L.10$Bhat/mash_data_L.10$Shat # obtain z
mash_data_L.center$Shat = matrix(1, nrow(mash_data_L.10$Bhat),ncol(mash_data_L.10$Bhat))
mash_data_L.center$Bhat = apply(mash_data_L.center$Bhat, 2, function(x) x - mean(x))
U.pca = cov_pca(mash_data_L.center,2,strong)
U.ed = cov_ed(mash_data_L.center, U.pca, strong)

mashcontrast.model.10 = mash(mash_data_L.10, c(U.c, U.ed), algorithm.version = 'R', verbose = FALSE)
```
Using `mashcommonbaseline`, there are `r length(get_significant_results(mashcontrast.model.10))` discoveries. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(mashcontrast.model.10),las = 2, cex.names = 0.7)
```
The correlation for PCA1 is:
```{r, echo=FALSE, fig.width=3, fig.height=3,fig.align='center'}
x           <- cov2cor(mashcontrast.model.10$fitted_g$Ulist[["ED_PCA_1"]])
x[x > 1]    <- 1
x[x < -1]   <- -1
colnames(x) <- colnames(get_lfsr(mashcontrast.model.10))
rownames(x) <- colnames(x)
corrplot.mixed(x,upper='color',cl.lim=c(-1,1), upper.col=colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(40),
               title='PCA1',mar=c(0,0,1.5,0))
```

Recover the last column
```{r}
mashcontrast.model.10.full = mashcontrast.model.10
mashcontrast.model.10.full$result = mash_compute_posterior_matrices(g = mashcontrast.model.10, data = mash_data_L.10, algorithm.version = 'R', recover=TRUE)
```

There are `r length(get_significant_results(mashcontrast.model.10.full))` discoveries.

## Subtract mean directly

If we subtract the mean from the data directly
$$Var(\hat{c}_{j,r}-\bar{\hat{c}_{j}}) = \frac{1}{2} - \frac{1}{2R}$$
```{r}
Indep.data.10 = mash_set_data(Bhat = mash_data_L.10$Bhat,
                           Shat = matrix(sqrt(0.5-1/(2*R)), nrow(data$Chat), R-1))

Indep.model.10 = mash(Indep.data.10, c(U.c, U.ed), algorithm.version = 'R', verbose = FALSE)
```
There are `r length(get_significant_results(Indep.model.10))` discoveries. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(Indep.model.10),las = 2, cex.names = 0.7)
```

The correlation for PCA2 and tPCA is:
```{r, echo=FALSE, fig.width=8, fig.height=3,fig.align='center'}
par(mfrow=c(1,2))
x           <- cov2cor(Indep.model.10$fitted_g$Ulist[["ED_PCA_2"]])
x[x > 1]    <- 1
x[x < -1]   <- -1
colnames(x) <- seq(1,9)
rownames(x) <- seq(1,9)
corrplot.mixed(x,upper='color',cl.lim=c(-1,1), upper.col=colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(40),
               title='PCA2',mar=c(0,0,1.5,0))

x           <- cov2cor(Indep.model.10$fitted_g$Ulist[["ED_tPCA"]])
x[x > 1]    <- 1
x[x < -1]   <- -1
colnames(x) <- seq(1,9)
rownames(x) <- seq(1,9)
corrplot.mixed(x,upper='color',cl.lim=c(-1,1), upper.col=colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(40),
               title='tPCA',mar=c(0,0,1.5,0))
par(mfrow=c(1,1))
```

Recover the last column
```{r}
Indep.model.10.full = Indep.model.10
Indep.model.10.full$result = mash_compute_posterior_matrices(g = Indep.model.10, data = Indep.data.10, algorithm.version = 'R', recover=TRUE)
```

There are `r length(get_significant_results(Indep.model.10.full))` discoveries.

# Discard the first column

The data was generated with signals in the first c conditions ($c_{j,1}, \cdots, c_{j,c}$). The contrast matrix L used here discards the last condition. The deviations are $\hat{c}_{j,1} - \bar{\hat{c}_{j}}, \hat{c}_{j,2} - \bar{\hat{c}_{j}}, \cdots, \hat{c}_{j,R-1} - \bar{\hat{c}_{j}}$.

However, the contrast matrix L can discard any deviation from $\hat{c}_{j,1} - \bar{\hat{c}_{j}}, \cdots, \hat{c}_{j,R} - \bar{\hat{c}_{j}}$. The choice of the discarded deviation could influence the reuslt.

We run the same model with L that discard the first deviation.

## Mash contrast model

```{r}
L.1 = L[2:R,]
row.names(L.1) = seq(2,R)
mash_data_L.1 = mash_set_data_contrast(mash_data, L.1)
```

```{r}
U.c = cov_canonical(mash_data_L.1)

# data driven
# select max
m.1by1 = mash_1by1(mash_data_L.1)
strong = get_significant_results(m.1by1,0.05)
# center Z
mash_data_L.center = mash_data_L.1
mash_data_L.center$Bhat = mash_data_L.1$Bhat/mash_data_L.1$Shat # obtain z
mash_data_L.center$Shat = matrix(1, nrow(mash_data_L.1$Bhat),ncol(mash_data_L.1$Bhat))
mash_data_L.center$Bhat = apply(mash_data_L.center$Bhat, 2, function(x) x - mean(x))
U.pca = cov_pca(mash_data_L.center,2,strong)
U.ed = cov_ed(mash_data_L.center, U.pca, strong)

mashcontrast.model.1 = mash(mash_data_L.1, c(U.c, U.ed), algorithm.version = 'R', verbose = FALSE)
```
Using `mashcommonbaseline` model, there are `r length(get_significant_results(mashcontrast.model.1))` discoveries. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(mashcontrast.model.1),las = 2, cex.names = 0.7)
```
The correlation PCA 1 is:
```{r, echo=FALSE, fig.width=3, fig.height=3,fig.align='center'}
x           <- cov2cor(mashcontrast.model.1$fitted_g$Ulist[["ED_PCA_1"]])
x[x > 1]    <- 1
x[x < -1]   <- -1
colnames(x) <- colnames(get_lfsr(mashcontrast.model.1))
rownames(x) <- colnames(x)
corrplot.mixed(x,upper='color',cl.lim=c(-1,1), upper.col=colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(40),
               title='PCA1',mar=c(0,0,1.5,0))
```

Recover the first column
```{r}
mashcontrast.model.1.full = mashcontrast.model.1
mashcontrast.model.1.full$result = mash_compute_posterior_matrices(g = mashcontrast.model.1, data = mash_data_L.1, algorithm.version = 'R', recover=TRUE)
```

There are `r length(get_significant_results(mashcontrast.model.1.full))` discoveries.

## Subtract mean directly

```{r}
Indep.data.1 = mash_set_data(Bhat = mash_data_L.1$Bhat,
                           Shat = matrix(sqrt(0.5-1/(R*2)), nrow(data$Chat), R-1))

Indep.model.1 = mash(Indep.data.1, c(U.c, U.ed), algorithm.version = 'R', verbose = FALSE)
```
For `mashIndep` model, there are `r length(get_significant_results(Indep.model.1))` discoveries. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(Indep.model.1),las = 2, cex.names = 0.7)
```

The correlation for PCA2 and tPCA is:
```{r, echo=FALSE, fig.width=8, fig.height=3,fig.align='center'}
par(mfrow=c(1,2))
x           <- cov2cor(Indep.model.1$fitted_g$Ulist[["ED_PCA_2"]])
x[x > 1]    <- 1
x[x < -1]   <- -1
colnames(x) <- seq(1,9)
rownames(x) <- seq(1,9)
corrplot.mixed(x,upper='color',cl.lim=c(-1,1), upper.col=colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(40),
               title='PCA2',mar=c(0,0,1.5,0))

x           <- cov2cor(Indep.model.1$fitted_g$Ulist[["ED_tPCA"]])
x[x > 1]    <- 1
x[x < -1]   <- -1
colnames(x) <- seq(1,9)
rownames(x) <- seq(1,9)
corrplot.mixed(x,upper='color',cl.lim=c(-1,1), upper.col=colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(40),
               title='tPCA',mar=c(0,0,1.5,0))
par(mfrow=c(1,1))
```

Recover the first column
```{r}
Indep.model.1.full = Indep.model.1
Indep.model.1.full$result = mash_compute_posterior_matrices(g = Indep.model.1, data = Indep.data.1, algorithm.version = 'R', recover=TRUE)
```

There are `r length(get_significant_results(Indep.model.1.full))` discoveries.

# Compare models

The RRMSE plot:
```{r}
delta.10 = data$C %*% t(L)
deltahat.10 = data$Chat %*% t(L)

delta.1 = delta.10[, c(2:10, 1)]
deltahat.1 = deltahat.10[, c(2:10, 1)]

barplot(c(sqrt(mean((delta.10 - mashcontrast.model.10.full$result$PosteriorMean)^2)/mean((delta.10 - deltahat.10)^2)), sqrt(mean((delta.1 - mashcontrast.model.1.full$result$PosteriorMean)^2)/mean((delta.1 - deltahat.1)^2)), sqrt(mean((delta.10 - Indep.model.10.full$result$PosteriorMean)^2)/mean((delta.10 - deltahat.10)^2)), sqrt(mean((delta.1 - Indep.model.1.full$result$PosteriorMean)^2)/mean((delta.1 - deltahat.1)^2))), ylim=c(0,0.2), names.arg = c('mashcommon.10','mashcommon.1','mash.indep.10', 'mash.indep.1'), ylab='RRMSE')
```

We check the False Positive Rate and True Positive Rate. 
$$FPR = \frac{|N\cap S|}{|N|} \quad TPR = \frac{|CS\cap S|}{|T|} $$

```{r}
CS_S = function(model, thresh=0.05, data){
  sig.index = model$result$lfsr <= thresh
  sum(sig.index * model$result$PosteriorMean * data > 0)
}

N_S = function(model, thresh=0.05, data){
  N.index = data == 0
  sig.index = model$result$lfsr <= thresh
  sum(sig.index * N.index)
}

delta.1[abs(delta.1) <= 1e-14] = 0
delta.10[abs(delta.10) <= 1e-14] = 0
N = sum(delta.1 == 0)
Tr = nrow(delta.1) * ncol(delta.1) - N

thresh.seq = seq(0, 1, by=0.0005)[-1]
mashcontrast.1 = matrix(0,length(thresh.seq), 2)
Indep.1 = matrix(0,length(thresh.seq), 2)
mashcontrast.10 = matrix(0,length(thresh.seq), 2)
Indep.10 = matrix(0,length(thresh.seq), 2)
colnames(mashcontrast.1) = c('TPR', 'FPR')
colnames(Indep.1) = c('TPR', 'FPR')
colnames(mashcontrast.10) = c('TPR', 'FPR')
colnames(Indep.10) = c('TPR', 'FPR')
for(t in 1:length(thresh.seq)){
  mashcontrast.1[t,] = c(CS_S(mashcontrast.model.1.full, thresh.seq[t], delta.1)/Tr, N_S(mashcontrast.model.1.full, thresh.seq[t],delta.1)/N)
  Indep.1[t,] = c(CS_S(Indep.model.1.full, thresh.seq[t], delta.1)/Tr,  N_S(Indep.model.1.full, thresh.seq[t],delta.1)/N)
  
  mashcontrast.10[t,] = c(CS_S(mashcontrast.model.10.full, thresh.seq[t], delta.10)/Tr, N_S(mashcontrast.model.10.full, thresh.seq[t],delta.10)/N)
  Indep.10[t,] = c(CS_S(Indep.model.10.full, thresh.seq[t], delta.10)/Tr,  N_S(Indep.model.10.full, thresh.seq[t],delta.10)/N)
}
```

```{r, echo=FALSE}
{plot(mashcontrast.1[,'FPR'], mashcontrast.1[,'TPR'], col='red',type='l',xlab = 'FPR', ylab='TPR', main='True Positive vs False Positive')
lines(mashcontrast.10[,'FPR'], mashcontrast.10[,'TPR'], col='green')
lines(Indep.1[,'FPR'], Indep.1[,'TPR'], col='blue')
lines(Indep.10[,'FPR'], Indep.10[,'TPR'])
legend('bottomright', c('mashcommon.1','mashcommon.10', 'mash.indep.1', 'mash.indep.10'),col=c('red','green', 'blue', 'black'),lty=c(1,1))}
```

The `mashcommonbaseline` model performs better than `mash.indep` model. The choice of the discarded column has larger effect for `mash.indep` model.

# Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
