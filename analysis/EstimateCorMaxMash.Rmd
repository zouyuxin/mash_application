---
title: "Estimate corâ€”max MASH"
author: "Yuxin Zou"
date: 2018-07-25
output: 
  workflowr::wflow_html:
    code_folding: hide
---

```{r library}
library(mashr)
source('../code/generateDataV.R')
source('../code/estimate_cor.R')
source('../code/summary.R')
library(knitr)
library(kableExtra)
library(ggplot2)
library(reshape2)
```

Apply the max likelihood methods for correlation matrix on mash data. 

After we estimate each pairwise correlation, the final resulting $p\times p$ correlation matrix may not be positive definite. I estimate the nearest PD cor matrix with `nearPD` function. **In the simulations, there is no non pd resulting matrix.**

The estimated V from optim(`optim` function), $M_{\rho}$ and $MV$ perform better than the truncated correlation (error, mash log likelihood, ROC).

Comparing the estimated V from optim, $M_{\rho}$ and $MV$, $MV$ algorithm is the fastest one, followed by $M_{\rho}$. The estimated V from optim and $M_{\rho}$ are very similar. They have smaller error to the true V than $MV$, most of the time. The estimated V from $MV$ has larger log likelihood in the final mash model. In terms of ROC and RRMSE, the estimated V from optim, $M_{\rho}$ and $MV$ performs similarly.

Based on the simulation results, I prefer the $MV$ method.

## One example: p = 3
$$
\hat{\beta}|\beta \sim N_{3}(\hat{\beta}; \beta, \left(\begin{matrix} 1 & 0.7 & 0.2 \\
                                          0.7 & 1 & 0.4 \\ 
                                          0.2 & 0.4 & 1 \end{matrix}\right))
$$

$$
\beta \sim \frac{1}{4}\delta_{0} + \frac{1}{4}N_{3}(0, \left(\begin{matrix} 1 & 0 &0\\
                                          0 & 0 & 0 \\
                                          0 & 0 & 0 \end{matrix}\right)) + \frac{1}{4}N_{3}(0, \left(\begin{matrix} 1 & 0 & 0 \\
                     0 & 1 & 0 \\
                     0 & 0 & 0 \end{matrix}\right)) + \frac{1}{4}N_{3}(0, \left(\begin{matrix} 1 & 1 & 1 \\
                     1 & 1 & 1 \\
                     1 & 1 & 1 \end{matrix}\right))
$$

```{r}
set.seed(1)
Sigma = cbind(c(1,0.7,0.2), c(0.7,1,0.4), c(0.2,0.4,1))
U0 = matrix(0,3,3)
U1 = matrix(0,3,3); U1[1,1] = 1
U2 = diag(3); U2[3,3] = 0
U3 = matrix(1,3,3)
data = generate_data(n=4000, p=3, V=Sigma, Utrue = list(U0=U0, U1=U1,U2=U2,U3=U3))
```

We find the estimate of V with canonical covariances and the PCA covariances.
```{r}
m.data = mash_set_data(data$Bhat, data$Shat)
m.1by1 = mash_1by1(m.data)
strong = get_significant_results(m.1by1)

U.pca = cov_pca(m.data, 3, subset = strong)
U.ed = cov_ed(m.data, U.pca, subset = strong)
U.c = cov_canonical(m.data)
```

The PCA correlation matrices are:
```{r echo=FALSE, fig.width=8, fig.height=4,fig.align='center'}
plotCor = function(U, title, condition_names = 1:nrow(U)){
  x           <- cov2cor(U)
  x[x > 1]    <- 1
  x[x < -1]   <- -1
  colnames(x) <- condition_names
  rownames(x) <- condition_names
  corrplot::corrplot.mixed(x,upper='color',cl.lim=c(-1,1), upper.col=colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(40),
                          title=title,mar=c(0,0,1.5,0))
}
par(mfrow=c(2,2))
plotCor(U.ed$ED_PCA_1, 'PCA1')
plotCor(U.ed$ED_PCA_2, 'PCA2')
plotCor(U.ed$ED_PCA_3, 'PCA3')
plotCor(U.ed$ED_tPCA, 'tPCA')
```

1. We run the algorithm in [estimate cor optim](EstimateCorOptim.html) with 3 different initial points for $\rho$, (-0.5,0,0.5). The $\rho$ in each iteration is estimated using `optim` function. The estimated correlation is

```{r, warning=FALSE}
Vhat.optim = estimateV(m.data, c(U.c, U.ed), init_rho = c(-0.5,0,0.5), tol=1e-4, optmethod = 'optim')
Vhat.optim$V
```

2. The result uses algorithm in [estimate cor mrho](EstimateCorEM3.html). $\rho$ in each iteration is the root of a third degree polynomial.

```{r, warning=FALSE}
Vhat.mrho = estimateV(m.data, c(U.c, U.ed), init_rho = c(-0.5,0,0.5), tol = 1e-4, optmethod = 'mrho')
Vhat.mrho$V
```

The running time (in sec.) for each pairwise correlation is 
```{r}
table = data.frame(rbind(Vhat.optim$ttime, Vhat.mrho$ttime), row.names = c('optim', 'mrho'))
colnames(table) = c('12','13','23')
table %>% kable() %>% kable_styling()
```
The time is the total running time with different initial point.

3. The result uses algorithm in [estimate cor mV](EstimateCorMaxMV.html).

```{r, warning=FALSE}
Vhat.mV = estimateV(m.data, c(U.c, U.ed), init_V = list(diag(ncol(m.data$Bhat)), clusterGeneration::rcorrmatrix(3), clusterGeneration::rcorrmatrix(3)), tol = 1e-4, optmethod = 'mV')
Vhat.mV$V
```

4. Using the original truncated correlation:
```{r}
Vhat.tru = estimate_null_correlation(m.data)
Vhat.tru
```

The truncated correlation underestimates the correlations.

5. mash 1by1: Run ash for each condition, and estimate correlation matrix based on the non-significant samples.

```{r}
V.mash = cor((data$Bhat/data$Shat)[-strong,])
V.mash
```

All the estimated correlation matrices above are positive definite.

### Error

Check the estimation error:
```{r}
FError = c(norm(Vhat.optim$V - Sigma, 'F'),
           norm(Vhat.mrho$V - Sigma, 'F'),
           norm(Vhat.mV$V - Sigma, 'F'),
           norm(Vhat.tru - Sigma, 'F'),
           norm(V.mash - Sigma, 'F'))
OpError = c(norm(Vhat.optim$V - Sigma, '2'),
           norm(Vhat.mrho$V - Sigma, '2'),
           norm(Vhat.mV$V - Sigma, '2'),
           norm(Vhat.tru - Sigma, '2'),
           norm(V.mash - Sigma, '2'))
table = data.frame(FrobeniusError = FError, SpectralError = OpError, row.names = c('optim','mrho','mV','trunc','m.1by1'))
table %>% kable() %>% kable_styling()
```

### mash log likelihood
In mash model, the model with correlation from optim has larger loglikelihood.

```{r}
m.data.optim = mash_set_data(data$Bhat, data$Shat, V=Vhat.optim$V)
m.model.optim = mash(m.data.optim, c(U.c,U.ed), verbose = FALSE)
```

```{r}
m.data.mrho = mash_set_data(data$Bhat, data$Shat, V=Vhat.mrho$V)
m.model.mrho = mash(m.data.mrho, c(U.c,U.ed), verbose = FALSE)
```

```{r}
m.data.mV = mash_set_data(data$Bhat, data$Shat, V=Vhat.mV$V)
m.model.mV = mash(m.data.mV, c(U.c,U.ed), verbose = FALSE)
```

```{r}
m.data.trunc = mash_set_data(data$Bhat, data$Shat, V=Vhat.tru)
m.model.trunc = mash(m.data.trunc, c(U.c,U.ed), verbose = FALSE)
```

```{r}
m.data.1by1 = mash_set_data(data$Bhat, data$Shat, V=V.mash)
m.model.1by1 = mash(m.data.1by1, c(U.c,U.ed), verbose = FALSE)
```

```{r}
m.data.correct = mash_set_data(data$Bhat, data$Shat, V=Sigma)
m.model.correct = mash(m.data.correct, c(U.c,U.ed), verbose = FALSE)
```

The results are summarized in table:
```{r}
null.ind = which(apply(data$B,1,sum) == 0)
V.trun = c(get_loglik(m.model.trunc), length(get_significant_results(m.model.trunc)), sum(get_significant_results(m.model.trunc) %in% null.ind))
V.optim = c(get_loglik(m.model.optim), length(get_significant_results(m.model.optim)), sum(get_significant_results(m.model.optim) %in% null.ind))
V.mrho = c(get_loglik(m.model.mrho), length(get_significant_results(m.model.mrho)), sum(get_significant_results(m.model.mrho) %in% null.ind))
V.mV = c(get_loglik(m.model.mV), length(get_significant_results(m.model.mV)), sum(get_significant_results(m.model.mV) %in% null.ind))
V.1by1 = c(get_loglik(m.model.1by1), length(get_significant_results(m.model.1by1)), sum(get_significant_results(m.model.1by1) %in% null.ind))
V.correct = c(get_loglik(m.model.correct), length(get_significant_results(m.model.correct)), sum(get_significant_results(m.model.correct) %in% null.ind))
temp = cbind(V.optim, V.mrho, V.mV, V.trun, V.1by1, V.correct)
colnames(temp) = c('optim','Mrho','MV', 'Truncate', 'm.1by1', 'True')
row.names(temp) = c('log likelihood', '# significance', '# False positive')
temp %>% kable() %>% kable_styling()
```

### ROC

```{r}
m.optim.seq = ROC.table(data$B, m.model.optim)
m.mrho.seq = ROC.table(data$B, m.model.mrho)
m.mV.seq = ROC.table(data$B, m.model.mV)
m.trun.seq = ROC.table(data$B, m.model.trunc)
m.1by1.seq = ROC.table(data$B, m.model.1by1)
m.correct.seq = ROC.table(data$B, m.model.correct)
```

```{r echo=FALSE, fig.align = "center"}
{plot(m.correct.seq[,'FPR'], m.correct.seq[,'TPR'],type='l',xlab = 'FPR', ylab='TPR', main='True Positive vs False Positive', cex=1.5, lwd = 1.5)
lines(m.optim.seq[,'FPR'], m.optim.seq[,'TPR'], col='red', lwd = 1.5)
lines(m.mrho.seq[,'FPR'], m.mrho.seq[,'TPR'], col='green', lwd = 1.5)
lines(m.mV.seq[,'FPR'], m.mV.seq[,'TPR'], col='purple', lwd = 1.5)
lines(m.trun.seq[,'FPR'], m.trun.seq[,'TPR'], col='blue', lwd = 1.5)
lines(m.1by1.seq[,'FPR'], m.1by1.seq[,'TPR'], col='cyan', lwd = 1.5)
legend('bottomright', c('True','optim','Mrho','MV','Trunc', 'm.1by1'),col=c('black','red','green','purple', 'blue', 'cyan'),lty=c(1,1,1,1,1,1), lwd=c(1.5,1.5,1.5,1.5,1.5, 1.5))}
```

### RRMSE

```{r}
rrmse = rbind(RRMSE(data$B, data$Bhat, list(m.model.optim, m.model.mrho, m.model.mV, m.model.trunc, m.model.1by1, m.model.correct)))
colnames(rrmse) = c('optim','Mrho','MV', 'Truncate','m.1by1','True')
row.names(rrmse) = 'RRMSE'
rrmse %>% kable() %>% kable_styling()
```

```{r}
barplot(rrmse, ylim=c(0,(1+max(rrmse))/2), names.arg = c('optim','Mrho', 'MV','Truncate','m.1by1','True'), las=2, cex.names = 0.7, main='RRMSE')
```

## More simulations: p = 5

I randomly generate 10 positive definite correlation matrices, V. The sample size is 4000.

$$
\hat{z}|z \sim N_{5}(z, V)
$$
$$
z\sim\frac{1}{4}\delta_{0} + \frac{1}{4}N_{5}(0,\left(\begin{matrix} 1 & \mathbf{0}_{1\times 4} \\ \mathbf{0}_{4\times 1} & \mathbf{0}_{4\times 4} \end{matrix}\right)) + \frac{1}{4}N_{5}(0,\left(\begin{matrix} \mathbf{1}_{2\times 2} & \mathbf{0}_{1\times 3} \\ \mathbf{0}_{3\times 1} & \mathbf{0}_{3\times 3} \end{matrix}\right)) + \frac{1}{4}N_{5}(0,\mathbf{1}_{5\times 5})
$$

```{r, warning=FALSE, eval=FALSE}
set.seed(100)
n=4000; p = 5
U0 = matrix(0,p,p)
U1 = U0; U1[1,1] = 1
U2 = U0; U2[c(1:2), c(1:2)] = 1
U3 = matrix(1, p,p)
Utrue = list(U0 = U0, U1 = U1, U2 = U2, U3 = U3)
for(t in 1:20){
  Vtrue = clusterGeneration::rcorrmatrix(p)
  data = generate_data(n, p, Vtrue, Utrue)
  # mash cov
  m.data = mash_set_data(Bhat = data$Bhat, Shat = data$Shat)
  m.1by1 = mash_1by1(m.data)
  strong = get_significant_results(m.1by1)

  U.pca = cov_pca(m.data, 3, subset = strong)
  U.ed = cov_ed(m.data, U.pca, subset = strong)
  U.c = cov_canonical(m.data)
  Vhat.optim <- estimateV(m.data, c(U.c, U.ed), init_rho = c(-0.5,0,0.5), tol=1e-4, optmethod = 'optim')
  Vhat.mrho <- estimateV(m.data, c(U.c, U.ed), init_rho = c(-0.5,0,0.5), tol=1e-4, optmethod = 'mrho')
  Vhat.mV <- estimateV(m.data, c(U.c, U.ed), init_V = list(diag(ncol(m.data$Bhat)), clusterGeneration::rcorrmatrix(p), clusterGeneration::rcorrmatrix(p)),tol=1e-4, optmethod = 'mV')
  saveRDS(list(V.true = Vtrue, V.optim = Vhat.optim, V.mrho = Vhat.mrho, V.mV = Vhat.mV, data = data, strong=strong),
          paste0('../output/MASH.result.',t,'.rds'))
}

```

```{r}
files = dir("../output/AddEMV/"); files = files[grep("MASH.result",files)]
times = length(files)
result = vector(mode="list",length = times)
for(i in 1:times) {
  result[[i]] = readRDS(paste("../output/AddEMV/", files[[i]], sep=""))
}
```

```{r warning=FALSE}
optim.pd = numeric(times)
mrho.pd = numeric(times)
for(i in 1:times){
  m.data = mash_set_data(result[[i]]$data$Bhat, result[[i]]$data$Shat)
  
  result[[i]]$V.trun = estimate_null_correlation(m.data, apply_lower_bound = FALSE)
  m.1by1 = mash_1by1(m.data)
  strong = get_significant_results(m.1by1)
  result[[i]]$V.1by1 = cor(m.data$Bhat[-strong,])
  U.c = cov_canonical(m.data)
  U.pca = cov_pca(m.data, 3, subset = strong)
  U.ed = cov_ed(m.data, U.pca, subset = strong)

  m.data.true = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = result[[i]]$V.true)
  m.model.true = mash(m.data.true, c(U.c,U.ed), verbose = FALSE)
  
  m.data.trunc = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = result[[i]]$V.trun)
  m.model.trunc = mash(m.data.trunc, c(U.c,U.ed), verbose = FALSE)
  
  m.data.1by1 = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = result[[i]]$V.1by1)
  m.model.1by1 = mash(m.data.1by1, c(U.c,U.ed), verbose = FALSE)
  
  m.data.mV = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = result[[i]]$V.mV$V)
  m.model.mV = mash(m.data.mV, c(U.c,U.ed), verbose = FALSE)
  
  # optim
  
  m.model.optim = m.model.optim.F = m.model.optim.2 = list()
  R <- tryCatch(chol(result[[i]]$V.optim$V),error = function (e) FALSE)
  if(is.matrix(R)){
    optim.pd[i] = 1
    m.data.optim = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = result[[i]]$V.optim$V)
    m.model.optim = mash(m.data.optim, c(U.c,U.ed), verbose = FALSE)
  }else{
    V.optim.near.F = as.matrix(Matrix::nearPD(result[[i]]$V.optim$V, conv.norm.type = 'F', keepDiag = TRUE)$mat)
    V.optim.near.2 = as.matrix(Matrix::nearPD(result[[i]]$V.optim$V, conv.norm.type = '2', keepDiag = TRUE)$mat)
    
    result[[i]]$V.optim.F = V.optim.near.F
    result[[i]]$V.optim.2 = V.optim.near.2
    
    # mashmodel
    m.data.optim.F = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = V.optim.near.F)
    m.model.optim.F = mash(m.data.optim.F, c(U.c,U.ed), verbose = FALSE)
    
    m.data.optim.2 = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = V.optim.near.2)
    m.model.optim.2 = mash(m.data.optim.2, c(U.c,U.ed), verbose = FALSE)
  }
  
  # Mrho
  m.model.mrho = m.model.mrho.F = m.model.mrho.2 = list()
  R <- tryCatch(chol(result[[i]]$V.mrho$V),error = function (e) FALSE)
  if(is.matrix(R)){
    mrho.pd[i] = 1
    m.data.mrho = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = result[[i]]$V.mrho$V)
    m.model.mrho = mash(m.data.mrho, c(U.c,U.ed), verbose = FALSE)
  }else{
    V.mrho.near.F = as.matrix(Matrix::nearPD(result[[i]]$V.mrho$V, conv.norm.type = 'F', keepDiag = TRUE)$mat)
    V.mrho.near.2 = as.matrix(Matrix::nearPD(result[[i]]$V.mrho$V, conv.norm.type = '2', keepDiag = TRUE)$mat)
    
    result[[i]]$V.mrho.F = V.mrho.near.F
    result[[i]]$V.mrho.2 = V.mrho.near.2
    
    # mashmodel
    m.data.mrho.F = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = V.mrho.near.F)
    m.model.mrho.F = mash(m.data.mrho.F, c(U.c,U.ed), verbose = FALSE)
      
    m.data.mrho.2 = mash_set_data(Bhat = m.data$Bhat, Shat = m.data$Shat, V = V.mrho.near.2)
    m.model.mrho.2 = mash(m.data.mrho.2, c(U.c,U.ed), verbose = FALSE)
  }
  
  result[[i]]$m.model = list(m.model.true = m.model.true, m.model.trunc = m.model.trunc, 
                             m.model.1by1 = m.model.1by1, m.model.mV = m.model.mV,
                             m.model.optim = m.model.optim,
                             m.model.optim.F = m.model.optim.F, m.model.optim.2 = m.model.optim.2, 
                             m.model.mrho = m.model.mrho,
                             m.model.mrho.F = m.model.mrho.F, m.model.mrho.2 = m.model.mrho.2)
}
```

### Error

The Frobenius norm is
```{r}
temp = matrix(0,nrow = times, ncol = 7)
for(i in 1:times){
  temp[i, ] = error.cor(result[[i]], norm.type='F', optim.pd = optim.pd[i], mrho.pd = mrho.pd[i])
}
colnames(temp) = c('Trunc','m.1by1', 'optim','optim.F', 'Mrho', 'Mrho.F', 'MV')
temp = reshape2::melt(temp[,c(-4,-6)])
colnames(temp) = c('Data', 'Method', 'FrobError')
ggplot(temp, aes(x = Data, y=FrobError, group = Method, color = Method)) + geom_line()
```

The spectral norm is
```{r}
temp = matrix(0,nrow = times, ncol = 7)
for(i in 1:times){
  temp[i, ] = error.cor(result[[i]], norm.type='2', optim.pd = optim.pd[i], mrho.pd = mrho.pd[i])
}
colnames(temp) = c('Trunc','m.1by1', 'optim','optim.2', 'Mrho', 'Mrho.2', 'MV')
temp = reshape2::melt(temp[,c(-4,-6)])
colnames(temp) = c('Data', 'Method', 'SpecError')
ggplot(temp, aes(x = Data, y=SpecError, group = Method, color = Method)) + geom_line()
```

### Time

The total running time for each matrix is
```{r}
optim.time = mrho.time = mV.time = numeric(times)
for(i in 1:times){
  optim.time[i] = sum(result[[i]]$V.optim$ttime)
  mrho.time[i] = sum(result[[i]]$V.mrho$ttime)
  mV.time[i] = sum(result[[i]]$V.mV$ttime)
}
temp = cbind(optim.time, mrho.time, mV.time)
colnames(temp) = c('optim', 'Mrho', 'mV')
row.names(temp) = 1:20

temp = melt(temp)
colnames(temp) = c('Data', 'Method', 'Time')
ggplot(temp, aes(x = Data, y=Time, group = Method, color = Method)) + geom_line()
```

### mash log likelihood

```{r}
temp = matrix(0,nrow = times, ncol = 10)
for(i in 1:times){
  temp[i, ] = loglik.cor(result[[i]]$m.model, optim.pd = optim.pd[i], mrho.pd = mrho.pd[i])
}
colnames(temp) = c('True', 'Trunc','m.1by1', 'optim','optim.F', 'optim.2', 'Mrho', 'Mrho.F', 'Mrho.2','MV')
temp = melt(temp[,-c(5,6,8,9)])
colnames(temp) = c('Data', 'Method', 'loglikelihood')
ggplot(temp, aes(x = Data, y=loglikelihood, group = Method, color = Method)) + geom_line()
```

### ROC

```{r}
par(mfrow=c(1,2))
for(i in 1:times){
  plotROC(result[[i]]$data$B, result[[i]]$m.model, optim.pd = optim.pd[i], mrho.pd = mrho.pd[i], title=paste0('Data', i, ' '))
}
```

### RRMSE

```{r}
par(mfrow=c(1,2))
for(i in 1:times){
  rrmse = rbind(RRMSE(result[[i]]$data$B, result[[i]]$data$Bhat, result[[i]]$m.model))
  barplot(rrmse, ylim=c(0,(1+max(rrmse))/2), las=2, cex.names = 0.7, main='RRMSE')
}
```
